{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKbpOPSGhSz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2bd2dea-3116-43d5-d9c9-996112812c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy_transformers in /usr/local/lib/python3.8/dist-packages (1.2.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy_transformers) (2.4.5)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy_transformers) (3.5.0)\n",
            "Requirement already satisfied: transformers<4.27.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy_transformers) (4.26.0)\n",
            "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.8/dist-packages (from spacy_transformers) (0.9.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from spacy_transformers) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy_transformers) (1.21.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (2.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (2.25.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (2.11.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (1.0.9)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (0.10.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (0.7.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (6.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (1.0.4)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (8.1.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (4.64.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (3.0.11)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (21.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (1.10.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->spacy_transformers) (4.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy_transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy_transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy_transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy_transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy_transformers) (0.12.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<4.0.0,>=3.4.0->spacy_transformers) (2.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.11)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "#RESUME SUMMARIZATION USING NLP\n",
        "#BSCS 3AB | GROUP  12 | CS353\n",
        "#COMPRA,IMEE\n",
        "#DALUMPINES, SOPHIA\n",
        "#DELOS REYES, CHRISTINE\n",
        "#FLOR, LEA\n",
        "\n",
        "\n",
        "# install spacy_transformers and update spacy library\n",
        "!pip install spacy_transformers\n",
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8h4cW97i3-b"
      },
      "outputs": [],
      "source": [
        "#Import necessary packages\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIFd099DjC56",
        "outputId": "a088fd4b-2857-4156-f03d-75b23cc74d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 31 05:41:46 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0    30W /  70W |    334MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1838      C                                     331MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnpgp1tkjNdU"
      },
      "outputs": [],
      "source": [
        "# load training data from a JSON file\n",
        "data = json.load(open('/content/ResumeSummarization/data/training/train_data.json', 'r'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq7UWWa_jY1d",
        "outputId": "6fd57284-aa94-41bb-c6da-b4d5c49cba47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# get the number of training data\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gpa5Y2X2jpRa",
        "outputId": "0ba297b7-c365-46cb-b0d9-bcc345eadb0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "# initialize a spacy model\n",
        "!python -m spacy init fill-config /content/ResumeSummarization/data/training/base_config.cfg config.cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq82lLMIj9E1",
        "outputId": "dd48ef7f-bf28-4bfd-9c69-e97d91b32a92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
              " {'entities': [[1749, 1755, 'Companies worked at'],\n",
              "   [1696, 1702, 'Companies worked at'],\n",
              "   [1417, 1423, 'Companies worked at'],\n",
              "   [1356, 1793, 'Skills'],\n",
              "   [1209, 1215, 'Companies worked at'],\n",
              "   [1136, 1247, 'Skills'],\n",
              "   [928, 932, 'Graduation Year'],\n",
              "   [858, 889, 'College Name'],\n",
              "   [821, 856, 'Degree'],\n",
              "   [787, 791, 'Graduation Year'],\n",
              "   [744, 750, 'Companies worked at'],\n",
              "   [722, 742, 'Designation'],\n",
              "   [658, 664, 'Companies worked at'],\n",
              "   [640, 656, 'Designation'],\n",
              "   [574, 580, 'Companies worked at'],\n",
              "   [555, 572, 'Designation'],\n",
              "   [470, 493, 'Companies worked at'],\n",
              "   [444, 468, 'Designation'],\n",
              "   [308, 314, 'Companies worked at'],\n",
              "   [234, 240, 'Companies worked at'],\n",
              "   [175, 198, 'Companies worked at'],\n",
              "   [93, 136, 'Email Address'],\n",
              "   [39, 48, 'Location'],\n",
              "   [13, 37, 'Designation'],\n",
              "   [0, 12, 'Name']]}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# show the n data in the training set\n",
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSpBlO7okFWa"
      },
      "outputs": [],
      "source": [
        "# define the function to get spaCy documents with entities\n",
        "def get_spacy_doc(file,input_data):\n",
        "    nlp = spacy.blank('en')\n",
        "    doc_bin = DocBin()\n",
        "    \n",
        "    # loop through the data to create spaCy documents with entities\n",
        "    for text, annotations in tqdm(input_data):\n",
        "        docu = nlp(text)\n",
        "        annotations = annotations['entities']\n",
        "        \n",
        "        entities = []\n",
        "        indices= []\n",
        "        \n",
        "        # loop through the entities to add them to the spaCy document\n",
        "        for start, end, label in annotations:\n",
        "            skip = False\n",
        "            for index in range(start, end):\n",
        "                if index in indices:\n",
        "                    skip = True\n",
        "                    break\n",
        "\n",
        "            # Skip the current entity if it overlaps with a previous entity        \n",
        "            if skip == True:\n",
        "                continue\n",
        "\n",
        "            # Add the indices of the current entity to the list    \n",
        "            indices = indices + list(range(start, end))\n",
        "            \n",
        "            try:\n",
        "                # Create a spaCy Span object from the start and end indices\n",
        "                span = docu.char_span(start, end, label=label, alignment_mode='strict')\n",
        "            except:\n",
        "                continue\n",
        "                \n",
        "            if span is None:\n",
        "                # Write the error information to the file\n",
        "                err_text = str([start, end]) + \"   \" + str(text) + \"\\n\"\n",
        "                file.write(err_text)\n",
        "                \n",
        "            else:\n",
        "                entities.append(span)\n",
        "                \n",
        "        try:\n",
        "            docu.ents = entities\n",
        "            doc_bin.add(docu)\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "    return doc_bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXARKrqOkJyi"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(data, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpb1vmoukNCr",
        "outputId": "1f4993c2-0f08-4d12-cd42-3d4889a93597"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Print the number of training and testing examples\n",
        "len(train_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpz0ArSqkQPt",
        "outputId": "24bf4241-61f7-417a-e01c-8a0890e4148e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 160/160 [00:01<00:00, 112.00it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 93.03it/s]\n"
          ]
        }
      ],
      "source": [
        "# Open a file to write error information\n",
        "file = open('err.txt', 'w', encoding='utf-8')\n",
        "\n",
        "# Get the spaCy DocBin for the training data and save it to disk\n",
        "train_bin = get_spacy_doc(file, train_data)\n",
        "train_bin.to_disk('train_data.spacy')\n",
        "\n",
        "# Get the spaCy DocBin for the testing data and save it to disk\n",
        "test_bin = get_spacy_doc(file, test_data)\n",
        "test_bin.to_disk('test_data.spacy')\n",
        "\n",
        "# Close the error file\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weno3Ih2kUrG",
        "outputId": "a79d0d7d-0975-422d-c02e-88e7bf6c01f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Print the number of tokens in the testing DocBin\n",
        "len(test_bin.tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w79D9oukXV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d6de4e-b412-4e0d-f8f6-8360913c96a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2023-01-31 05:45:04,466] [INFO] Set up nlp object from config\n",
            "INFO:spacy:Set up nlp object from config\n",
            "[2023-01-31 05:45:04,476] [INFO] Pipeline: ['transformer', 'ner']\n",
            "INFO:spacy:Pipeline: ['transformer', 'ner']\n",
            "[2023-01-31 05:45:04,479] [INFO] Created vocabulary\n",
            "INFO:spacy:Created vocabulary\n",
            "[2023-01-31 05:45:04,480] [INFO] Finished initializing nlp object\n",
            "INFO:spacy:Finished initializing nlp object\n",
            "Downloading (…)lve/main/config.json: 100% 481/481 [00:00<00:00, 82.5kB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 899k/899k [00:01<00:00, 669kB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:01<00:00, 413kB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 1.36M/1.36M [00:01<00:00, 1.02MB/s]\n",
            "Downloading (…)\"pytorch_model.bin\";: 100% 501M/501M [00:02<00:00, 185MB/s]\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2023-01-31 05:45:51,662] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "INFO:spacy:Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        5021.84   1432.76    0.15    0.08    3.32    0.00\n",
            "  3     200      347997.01  66921.25   33.23   38.00   29.52    0.33\n",
            "  7     400       64119.88  25269.84   54.66   53.64   55.72    0.55\n",
            " 10     600       10470.91  18908.09   59.21   53.41   66.42    0.59\n",
            " 14     800        6536.93  19352.58   58.64   59.36   57.93    0.59\n",
            " 17    1000        3050.12  15901.16   60.16   58.94   61.44    0.60\n",
            " 21    1200        1734.63  16315.55   56.89   59.60   54.43    0.57\n",
            " 24    1400        1331.64  14089.85   60.24   64.56   56.46    0.60\n",
            " 28    1600       79997.68  16402.25   61.83   67.03   57.38    0.62\n",
            " 31    1800       10216.92  13303.26   59.86   64.67   55.72    0.60\n",
            " 35    2000       13507.34  13745.60   60.61   54.86   67.71    0.61\n",
            " 38    2200        3075.72  12069.79   59.54   64.92   54.98    0.60\n",
            " 42    2400         479.05  12274.72   57.62   55.46   59.96    0.58\n",
            " 45    2600         722.87  10828.77   59.98   69.16   52.95    0.60\n",
            " 49    2800       34377.46  11276.57   57.42   51.00   65.68    0.57\n",
            " 52    3000        1867.86   9330.40   60.66   66.30   55.90    0.61\n",
            " 56    3200        3887.33   9295.57   58.95   55.45   62.92    0.59\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ],
      "source": [
        "#Train the model with the training data and config file\n",
        "!python -m spacy train config.cfg --output ./output --paths.train ./train_data.spacy --paths.dev ./test_data.spacy --gpu-id 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUxtuubwmCtN"
      },
      "outputs": [],
      "source": [
        "#Load the best model from the training output\n",
        "nlp_model = spacy.load('/content/output/model-best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxfEq7ZgmPpM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc2ce90-0943-4e11-d885-cf813c0d447a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name :  Phoebe Buffay\n",
            "Companies worked at :  Microsoft\n"
          ]
        }
      ],
      "source": [
        "#Apply the loaded model to the test sentence\n",
        "doc = nlp_model('My name is Phoebe Buffay. I worked at Microsoft for 15 years. I have expertise in Web Development and Software Engineering.')\n",
        "for ent in doc.ents:\n",
        "  print(ent.label_.replace(\" \", \" \") + \" : \", ent.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6rXVfcG9Xoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cffb7cdd-c8df-4b58-93d5-b7bfa745a4e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.8/dist-packages (1.21.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G3ibHu493gS"
      },
      "outputs": [],
      "source": [
        "import sys, fitz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fil2Cw4S979j"
      },
      "outputs": [],
      "source": [
        "file_name = '/content/ResumeSummarization/data/test/Flor-CV.pdf'\n",
        "pdf = fitz.open(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-1J6p8E-Eih"
      },
      "outputs": [],
      "source": [
        "text = \" \"\n",
        "#Loop through the pages in the pdf and add their content to the content variable\n",
        "for page in pdf:\n",
        "  text = text + str(page.get_text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8AsGBwD-OKQ"
      },
      "outputs": [],
      "source": [
        "#Replace multiple spaces with a single space\n",
        "text = ' '.join(text.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "S_9Seeea_ywh",
        "outputId": "a08ae21f-b1fd-46a8-eea3-e93326477ee6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Lea Flor Programmer Manila, Philippines ● 4 years of experience in programming ● Waitressing: Answer customer inquiries and resolve issues, and consistently adhered to quality expectations and standards WORK EXPERIENCE Junior Engineer Teleperformance – Manila May 2015 to September 2019 EDUCATION Technological University of the Philippines SKILLS Programmming'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzXXEvWd_9Mh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd73a0fc-5022-47cc-a7b1-17acb880bcac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name :  Lea Flor\n",
            "Location :  Manila\n",
            "Years of Experience :  4 years\n",
            "Designation :  Junior Engineer\n",
            "Location :  Manila\n",
            "College Name :  Technological University of the Philippines\n"
          ]
        }
      ],
      "source": [
        "#Apply the loaded NLP model to the content of the pdf file\n",
        "doc = nlp_model(text)\n",
        "for ent in doc.ents:\n",
        "  print(ent.label_.replace(\" \", \" \") + \" : \", ent.text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}